
"""
Batch sync using the working synchronous approach
"""
import requests
import pandas as pd
import json
import time
import os
from datetime import date, timedelta

# Create data directory if it doesn't exist
os.makedirs('data', exist_ok=True)

# è·å–å½“å‰è„šæœ¬çš„ç»å¯¹è·¯å¾„
current_script_path = os.path.abspath(__file__)
# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
current_script_dir = os.path.dirname(current_script_path)
# è·å–çˆ¶ç›®å½•
parent_dir = os.path.dirname(current_script_dir)
# æ„å»ºall_LOF.txtåœ¨çˆ¶ç›®å½•ä¸­çš„è·¯å¾„
lof_file_path = os.path.join(parent_dir, 'all_LOF.txt')

with open(lof_file_path, 'r', encoding='utf-8') as f:
    lof_codes = [line.strip() for line in f if line.strip()]

print(f"ğŸ“‹ Found {len(lof_codes)} LOF codes")

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept': 'application/json, text/javascript, */*; q=0.01',
    'X-Requested-With': 'XMLHttpRequest',
}

params = {
    '___jsl': 'LST___t',
    'rp': '50',
    'page': '1'
}

def fetch_lof_data(code):
    """Fetch LOF data using synchronous requests - save all columns"""
    url = f"https://www.jisilu.cn/data/lof/hist_list/{code}"
    
    try:
        response = requests.get(url, params=params, headers=headers, timeout=30)
        
        if response.status_code == 200:
            data = response.json()
            
            # Extract rows
            rows = data.get('rows', [])
            
            if rows:
                # Convert to dataframe with all columns
                records = []
                for row in rows:
                    cell = row['cell']
                    # Save all data from cell as-is
                    record = dict(cell)  # Copy all fields
                    record['code'] = code  # Add code for reference
                    records.append(record)
                
                df = pd.DataFrame(records)
                
                # Save to CSV with all columns
                filename = f"data/lof_{code}.csv"
                df.to_csv(filename, index=False, encoding='utf-8-sig')
                print(f"âœ… Saved {len(records)} records for {code}")
                return len(records)
            else:
                print(f"âš ï¸ No data for {code}")
                return 0
        else:
            print(f"âŒ HTTP {response.status_code} for {code}")
            return 0
            
    except Exception as e:
        print(f"âŒ Error for {code}: {e}")
        return 0

def main():
    print("ğŸš€ Starting batch sync for all LOF codes...")
    print("=" * 50)
    
    total_records = 0
    successful_codes = 0
    failed_codes = []
    
    for i, code in enumerate(lof_codes, 1):
        print(f"[{i:2d}/{len(lof_codes)}] Processing {code}...")
        
        count = fetch_lof_data(code)
        if count > 0:
            total_records += count
            successful_codes += 1
        else:
            failed_codes.append(code)
        
        # Add small delay to be respectful
        time.sleep(1)
    
    print("=" * 50)
    print(f"ğŸ¯ BATCH SYNC COMPLETE")
    print(f"ğŸ“Š Total records: {total_records}")
    print(f"âœ… Successful codes: {successful_codes}")
    print(f"âŒ Failed codes: {len(failed_codes)}")
    
    if failed_codes:
        print(f"Failed codes: {failed_codes}")

if __name__ == "__main__":
    main()